templates:
  fast-cpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 60
        use_gpu: false
        excluded_models:
          - NN_TORCH
  dev-cpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 300
        use_gpu: false
  dev-gpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 300
        use_gpu: true
  tabicl-fast:
    model: tabicl_skrub
    config:
      model:
        sample_fraction: 0.1
        cv_folds: 3
        n_estimators: 8
        batch_size: 4
        device: cuda
        norm_methods:
          - none
          - power
        output_labels: true
        label_threshold: 0.5
      hyperparameters:
        use_gpu: true
  tabicl-full:
    model: tabicl_skrub
    config:
      model:
        sample_fraction: 1.0
        cv_folds: 1
        n_estimators: 32
        batch_size: 8
        device: cuda
        norm_methods:
          - none
          - power
          - quantile
        output_labels: true
        label_threshold: 0.5
      hyperparameters:
        use_gpu: true
  best-cpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe00:
    model: autogluon_features_00
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-gpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: true
  extreme-gpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: extreme_quality
        time_limit: 86400
        use_gpu: true
  time8-cpu:
    model: autogluon_baseline
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800
        use_gpu: false
  best-cpu-fe01:
    model: autogluon_features_01
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe02:
    model: autogluon_features_02
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe03:
    model: autogluon_features_03
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe04:
    model: autogluon_features_04
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe05:
    model: autogluon_features_05
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe06:
    model: autogluon_features_06
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe07:
    model: autogluon_features_07
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe08:
    model: autogluon_features_08
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe09:
    model: autogluon_features_09
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe10:
    model: autogluon_features_10
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-rich-baseline:
    model: autogluon_features_rich_baseline
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
  best-cpu-lgbm-fe-rich:
    model: lgbm_fe_rich
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-xgb-fe-rich:
    model: xgb_fe_rich_model
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  best-cpu-fe-rich:
    model: autogluon_fe_rich
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 3600
        use_gpu: false
  eda-cpu:
    model: autogluon_eda_features
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 600
        use_gpu: false
  tuned-cpu:
    model: autogluon_tuned
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 600
        use_gpu: false
      model:
        num_trials: 10
        searcher: auto
  eda-8h-cpu:
    model: autogluon_eda_features
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800
        use_gpu: false
      model:
        leaderboard_rows: 20
  eda-8h-gpu:
    model: autogluon_eda_features
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800
        use_gpu: true
      model:
        leaderboard_rows: 20

  # Quick smoke tests for new TE+bagging variants (5 min, medium, minimal folds)
  dev-fe23-te:
    model: autogluon_features_23_target_bagging
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 300
        use_gpu: false
        num_bag_folds: 2
        num_stack_levels: 1
      model:
        target_encoding_folds: 4
        target_encoding_smoothing: 1.0
        enable_woe: true
  dev-fe24-te:
    model: autogluon_features_24_target_bagging_nowoe
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 300
        use_gpu: false
        num_bag_folds: 2
        num_stack_levels: 1
      model:
        target_encoding_folds: 4
        target_encoding_smoothing: 1.5
        enable_woe: false
  # ===================================================================
  # SERIA 5 EKSPERYMENTÓW - Feature Engineering & Model Optimization
  # ===================================================================
  exp01-tier1:
    model: exp01_tier1_features
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 5400  # 1.5h
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: false
      preprocessing:
        feature_set: tier1_critical
  exp02-encoding:
    model: exp02_tier2_encoding
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 5400  # 1.5h
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: false
      preprocessing:
        feature_set: tier2_encoding
        include_tier1: true
  exp03-lgbm-optuna:
    model: exp03_lgbm_optuna
    config:
      hyperparameters:
        n_trials: 50
        n_folds: 5
        early_stopping_rounds: 50
        verbose_eval: 100
        use_gpu: false
      preprocessing:
        feature_set: tier1_critical
  exp04-stacking:
    model: exp04_stacking_ensemble
    config:
      hyperparameters:
        n_folds: 5
        early_stopping_rounds: 50
        base_model_iterations: 500
        use_gpu: false
      preprocessing:
        feature_set: tier2_encoding
        include_tier1: true
  exp05-transfer:
    model: exp05_transfer_learning
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 5400
        pretrain_time_limit: 1800
        finetune_time_limit: 3600
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: false
      preprocessing:
        feature_set: tier1_with_transfer
        use_original_dataset: true

  best-cpu-fe11:
    model: autogluon_features_11
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe12:
    model: autogluon_features_12
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe13:
    model: autogluon_features_13
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe14:
    model: autogluon_features_14
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe15:
    model: autogluon_features_15
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe16:
    model: autogluon_features_16
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe17:
    model: autogluon_features_17
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe18:
    model: autogluon_features_18
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe19:
    model: autogluon_features_19
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH
  best-cpu-fe20:
    model: autogluon_features_20
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 7200
        use_gpu: false
        excluded_models:
          - NN_TORCH

  # ===================================================================
  # ULTIMATE OPTIMIZATION - FE21 & FE22
  # ===================================================================
  best-cpu-fe21:
    model: autogluon_features_21
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 21600
        num_bag_folds: 8
        num_stack_levels: 2
        use_gpu: false
        excluded_models:
          - NN_TORCH
      model:
        leaderboard_rows: 30

  best-cpu-fe22:
    model: autogluon_features_22_target_encoding
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 21600
        num_bag_folds: 8
        num_stack_levels: 2
        use_gpu: false
        excluded_models:
          - NN_TORCH
      model:
        leaderboard_rows: 30

  best-cpu-fe23:
    model: autogluon_features_23_target_bagging
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800
        num_bag_folds: 8
        num_stack_levels: 2
        use_gpu: false
        excluded_models:
          - NN_TORCH
      model:
        leaderboard_rows: 40
        target_encoding_folds: 5
        target_encoding_smoothing: 1.0
        enable_woe: true

  best-cpu-fe24:
    model: autogluon_features_24_target_bagging_nowoe
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800
        num_bag_folds: 8
        num_stack_levels: 2
        use_gpu: false
        excluded_models:
          - NN_TORCH
      model:
        leaderboard_rows: 40
        target_encoding_folds: 6
        target_encoding_smoothing: 2.0
        enable_woe: false

  best-gpu-fe25-fastai:
    model: autogluon_features_25_fastai
    config:
      hyperparameters:
        presets: null  # explicit FastAI config below
        time_limit: 3600
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: true
        included_model_types:
          - FASTAI
        ag_args_fit:
          num_gpus: 1
          device: cuda
          batch_size: 256
          num_workers: 0
          epochs: 15
        FASTAI:
          - ag_args:
              name_suffix: "_gpu"
            ag_args_fit:
              num_gpus: 1
              device: cuda
              batch_size: 256
              num_workers: 0
              epochs: 15
        feature_prune_kwargs: {}  # enable iterative feature pruning with defaults
      model:
        leaderboard_rows: 30
        target_encoding_folds: 6
        target_encoding_smoothing: 2.0
        enable_woe: false

  best-gpu-nn-only:
    model: autogluon_features_24_target_bagging_nowoe
    config:
      hyperparameters:
        presets: null
        time_limit: 3600
        use_gpu: true
        included_model_types: ["NN_TORCH"]
        NN_TORCH:
          - {}
          - activation: elu
            dropout_prob: 0.10
            hidden_size: 108
            learning_rate: 0.0027
            num_layers: 4
            use_batchnorm: true
            weight_decay: 1.3e-12
            ag_args:
              name_suffix: "_r79"
              priority: -2
            ag_args_fit:
              num_gpus: 1
              batch_size: 256
              num_workers: 0
          - activation: elu
            dropout_prob: 0.12
            hidden_size: 213
            learning_rate: 0.0010
            num_layers: 4
            use_batchnorm: false
            weight_decay: 5.6e-10
            ag_args:
              name_suffix: "_r22"
              priority: -7
            ag_args_fit:
              num_gpus: 1
              batch_size: 256
              num_workers: 0
        ag_args_ensemble:
          fold_fitting_strategy: sequential_local
        # Uncomment to add light HPO:
        # hyperparameter_tune_kwargs:
        #   num_trials: 4
        #   scheduler: local
        #   searcher: random
      model:
        leaderboard_rows: 30
        target_encoding_folds: 6
        target_encoding_smoothing: 2.0
        enable_woe: false

  # ===================================================================
  # ENSEMBLE MODELS
  # ===================================================================
  ensemble-best:
    model: ensemble_best_models
    config:
      hyperparameters:
        presets: null
        time_limit: null
        use_gpu: false
      model:
        ensemble_method: weighted_average
        calibration: false
        power: 2.0
        models:
          - name: fe17_log_EMI
            path: experiments/*/artifacts/best-cpu-fe17-autogluon_features_17
            weight: 0.30
            public_score: 0.92356
          - name: fe20_student_debt
            path: experiments/*/artifacts/best-cpu-fe20-autogluon_features_20
            weight: 0.25
            public_score: 0.92353
          - name: original_best
            path: AutogluonModels
            weight: 0.45
            public_score: 0.92434

  ensemble-ultimate:
    model: ensemble_best_models
    config:
      hyperparameters:
        presets: null
        time_limit: null
        use_gpu: false
      model:
        ensemble_method: weighted_average
        calibration: true
        power: 2.0
        models:
          - name: fe17_log_EMI
            path: experiments/*/artifacts/best-cpu-fe17-autogluon_features_17
            weight: 0.25
            public_score: 0.92356
          - name: fe20_student_debt
            path: experiments/*/artifacts/best-cpu-fe20-autogluon_features_20
            weight: 0.20
            public_score: 0.92353
          - name: fe21_ultimate
            path: experiments/*/artifacts/best-cpu-fe21-autogluon_features_21
            weight: 0.25
            public_score: null
          - name: fe22_target_encoded
            path: experiments/*/artifacts/best-cpu-fe22-autogluon_features_22_target_encoding
            weight: 0.20
            public_score: null
          - name: original_best
            path: AutogluonModels
            weight: 0.10
            public_score: 0.92434

  # ===================================================================
  # FEATURE PRUNING EXPERIMENTS - Automatic feature selection
  # ===================================================================

  # Quick test - XGB + GBM (for pruning) (3 min)
  quick-test-xgb-pruned:
    model: autogluon_baseline_pruned
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 180
        num_bag_folds: 3
        num_stack_levels: 0
        use_gpu: false
        included_model_types:
          - XGB
          - GBM  # Required for feature pruning!
          - CAT
      feature_prune:
        enabled: true
        force_prune: true
        prune_ratio: 0.05
        stopping_round: 10
        min_improvement: 1.0e-5
        max_fits: null
        seed: 42
        raise_exception: false
      model:
        leaderboard_rows: 5

  # Pruning + top 10 engineered features from best variants (same config as quick-test)
  best-cpu-prune01:
    model: autogluon_prune01
    config:
      hyperparameters:
        presets: medium_quality
        time_limit: 180
        num_bag_folds: 3
        num_stack_levels: 0
        use_gpu: false
        included_model_types:
          - XGB
          - GBM  # Required for feature pruning!
          - CAT
      feature_prune:
        enabled: true
        force_prune: true
        prune_ratio: 0.05
        stopping_round: 10
        min_improvement: 1.0e-5
        max_fits: null
        seed: 42
        raise_exception: false
      model:
        leaderboard_rows: 5

  # Baseline + Minimal FE + Pruning (clean start approach)
  best-cpu-baseline-pruned:
    model: autogluon_baseline_pruned
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800  # 8 hours
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: false
        excluded_models:
          - NN_TORCH
      feature_prune:
        enabled: true
        # Core pruning control
        force_prune: true           # Force all models to use pruned features
        time_limit: null            # Auto-calculated as 30% of total time (8640s)

        # Data sampling
        max_train_samples: 50000    # Max training rows for pruning model
        min_fi_samples: 10000       # Min validation rows for feature importance

        # Pruning thresholds
        prune_threshold: noise      # 'noise' or float - importance threshold
        prune_ratio: 0.05           # 5% worst features per round

        # Stopping criteria
        stopping_round: 50          # Stop after N rounds without improvement (time limit likely hits first)
        min_improvement: 1.0e-5     # Minimum relative score improvement (0.001%)
        max_fits: null              # Max model fits (null = unlimited)

        # Reproducibility
        seed: 42
        raise_exception: false      # Don't crash on errors
      model:
        leaderboard_rows: 30

  # Baseline + Minimal FE + Pruning + GPU (clean start approach with GPU acceleration)
  best-gpu-baseline-pruned:
    model: autogluon_baseline_pruned
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800  # 8 hours
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: true
        excluded_models:
          - NN_TORCH
      feature_prune:
        enabled: true
        # Core pruning control
        force_prune: true           # Force all models to use pruned features
        time_limit: null            # Auto-calculated as 30% of total time (8640s)

        # Data sampling
        max_train_samples: 50000    # Max training rows for pruning model
        min_fi_samples: 10000       # Min validation rows for feature importance

        # Pruning thresholds
        prune_threshold: noise      # 'noise' or float - importance threshold
        prune_ratio: 0.05           # 5% worst features per round

        # Stopping criteria
        stopping_round: 50          # Stop after N rounds without improvement (time limit likely hits first)
        min_improvement: 1.0e-5     # Minimum relative score improvement (0.001%)
        max_fits: null              # Max model fits (null = unlimited)

        # Reproducibility
        seed: 42
        raise_exception: false      # Don't crash on errors
      model:
        leaderboard_rows: 30

  # Rich Features + Pruning (noise removal approach)
  best-cpu-fe-pruned:
    model: autogluon_features_pruned
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 43200  # 12 hours
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: false
        excluded_models:
          - NN_TORCH
      feature_prune:
        enabled: true
        # Core pruning control
        force_prune: true           # Force all models to use pruned features
        time_limit: null            # Auto-calculated as 30% of total time (12960s)

        # Data sampling
        max_train_samples: 50000    # Max training rows for pruning model
        min_fi_samples: 10000       # Min validation rows for feature importance

        # Pruning thresholds
        prune_threshold: noise      # 'noise' or float - importance threshold
        prune_ratio: 0.05           # 5% worst features per round

        # Stopping criteria
        stopping_round: 50          # Stop after N rounds without improvement (time limit likely hits first)
        min_improvement: 1.0e-5     # Minimum relative score improvement (0.001%)
        max_fits: null              # Max model fits (null = unlimited)

        # Reproducibility
        seed: 42
        raise_exception: false      # Don't crash on errors
      model:
        leaderboard_rows: 30

  # Comprehensive Notebook Features + Pruning (from s5e11-single-xgboost-advanced-fe.ipynb)
  # FIXED: Corrected parameter names to match AutoGluon API:
  #   - time_limit → feature_prune_time_limit (was ambiguous with hyperparameters.time_limit)
  #   - Added n_fi_subsample as separate parameter (was missing, different from min_fi_samples)
  #   - Kept min_fi_samples as separate parameter per AutoGluon tests
  best-cpu-prune02:
    model: autogluon_prune02
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800  # 8 hours - TOTAL training time (passed to predictor.fit())
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: false
        included_model_types:
          - XGB
          - GBM  # Required for feature pruning!
          - CAT
      feature_prune:
        enabled: true
        # Core pruning control
        force_prune: true                    # Force all models to use pruned features
        feature_prune_time_limit: null       # Time for pruning only (auto = 30% of total = ~8640s)

        # Data sampling - 3 separate parameters per AutoGluon API
        max_train_samples: 100000            # n_train_subsample: samples for training pruning model
        n_fi_subsample: 30000                # Samples for computing feature importance (FI)
        min_fi_samples: 10000                # Minimum validation samples threshold for FI

        # Pruning thresholds - MORE CONSERVATIVE for careful feature removal
        prune_threshold: noise               # 'noise' or float - importance threshold
        prune_ratio: 0.01                    # 1% worst features per round

        # Stopping criteria - MORE ITERATIONS for thorough refinement
        stopping_round: 100                  # Stop after 100 rounds without improvement
        min_improvement: 1.0e-5              # Minimum relative score improvement (0.001%)
        max_fits: null                       # Max model fits (null = unlimited)

        # Reproducibility
        seed: 42
        raise_exception: false               # Don't crash on errors
      model:
        leaderboard_rows: 30

  # Comprehensive Notebook Features + Pruning + GPU (from s5e11-single-xgboost-advanced-fe.ipynb)
  # FIXED: Same corrections as best-cpu-prune02 (see comments above)
  best-gpu-prune02:
    model: autogluon_prune02
    config:
      hyperparameters:
        presets: best_quality
        time_limit: 28800  # 8 hours - TOTAL training time (passed to predictor.fit())
        num_bag_folds: 5
        num_stack_levels: 1
        use_gpu: true
        included_model_types:
          - XGB
          - GBM  # Required for feature pruning!
          - CAT
      feature_prune:
        enabled: true
        # Core pruning control
        force_prune: true                    # Force all models to use pruned features
        feature_prune_time_limit: null       # Time for pruning only (auto = 30% of total = ~8640s)

        # Data sampling - 3 separate parameters per AutoGluon API
        max_train_samples: 100000            # n_train_subsample: samples for training pruning model
        n_fi_subsample: 30000                # Samples for computing feature importance (FI)
        min_fi_samples: 10000                # Minimum validation samples threshold for FI

        # Pruning thresholds - MORE CONSERVATIVE for careful feature removal
        prune_threshold: noise               # 'noise' or float - importance threshold
        prune_ratio: 0.01                    # 1% worst features per round

        # Stopping criteria - MORE ITERATIONS for thorough refinement
        stopping_round: 100                  # Stop after 100 rounds without improvement
        min_improvement: 1.0e-5              # Minimum relative score improvement (0.001%)
        max_fits: null                       # Max model fits (null = unlimited)

        # Reproducibility
        seed: 42
        raise_exception: false               # Don't crash on errors
      model:
        leaderboard_rows: 30
