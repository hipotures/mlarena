# Raport: Analiza konkursu *Kaggle Playground Series S5E11 – Predicting Loan Payback*

## Dodatkowe źródła danych (oryginalny zbiór danych i inne)

Konkurs **Playground S5E11 – Predicting Loan Payback** wykorzystuje **syntetyczny zbiór danych** wygenerowany na podstawie wcześniejszego zbioru (tzw. „oryginalnego” zbioru Loan Prediction z 2025 roku). Zgodnie z informacjami Kaggle, rozkłady cech w danych konkursowych są **podobne, lecz nie identyczne** jak w zbiorze oryginalnym[\[1\]](https://github.com/mateuszk098/kaggle-notebooks#:~:text=%2A%20Playground%20Series%20S3E09%20,s3e9). Organizatorzy zachęcają uczestników do korzystania z oryginalnego zbioru w celach porównawczych, a nawet do ewentualnego włączenia go do treningu modeli (jeśli to pomaga w poprawie wyników). Oryginalny zestaw danych – opublikowany jako *Loan Prediction Dataset 2025* – zawiera ok. **20 tysięcy rekordów** i 22 kolumny (21 cech \+ kolumna docelowa). Dla porównania, dane konkursowe są dużo obszerniejsze (ok. **594 tysięcy przykładów**) i zawierają podzbiór cech (lub cechy przekształcone) z tamtego zbioru[\[2\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Target%20Distribution%3A%20loan_paid_back%20%3D%201,2)[\[3\]](https://www.kaggle.com/code/ocwerfrancis/predicting-loan-payback#:~:text=,monthly_income%27%2C%20%27employment_status%27%2C%20%27debt_to_income_ratio%27%2C%20%27credit_score).

**Oryginalny zbiór Loan Prediction 2025** obejmuje bogaty zestaw atrybutów opisujących aplikacje pożyczkowe. Znalazły się w nim m.in.: age (wiek pożyczkobiorcy), gender (płeć), marital\_status (stan cywilny), education\_level (poziom wykształcenia), annual\_income (roczny dochód), monthly\_income (miesięczny dochód), employment\_status (status zatrudnienia), debt\_to\_income\_ratio (wskaźnik DTI), credit\_score (ocena kredytowa), loan\_amount (kwota pożyczki), interest\_rate (oprocentowanie), loan\_purpose (cel pożyczki), grade oraz subgrade (kategorie jakości kredytu), a także kilka wskaźników historii kredytowej jak liczba zaległości czy zapisy w rejestrach publicznych[\[3\]](https://www.kaggle.com/code/ocwerfrancis/predicting-loan-payback#:~:text=,monthly_income%27%2C%20%27employment_status%27%2C%20%27debt_to_income_ratio%27%2C%20%27credit_score)[\[4\]](https://www.kaggle.com/code/stpeteishii/loan-payback-importance-compe-orgin-comparison#:~:text=...%20loan_dataset_20000.csv%27%29%20,current_balance%27%2C%20%27num_of_delinquencies%27%2C%20%27loan_term%27%2C%20%27public_records). Kolumną docelową jest zmienna binarna loan\_paid\_back, wskazująca czy pożyczka została spłacona. Warto zauważyć, że oryginalny zbiór również był **danych syntetycznych** stworzonych na potrzeby konkursu (a nie prawdziwymi danymi bankowymi)[\[5\]](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/615065#:~:text=The%20origin%20dataset%20is%20here,So). Oznacza to, że ewentualne zewnętrzne źródła (np. rzeczywiste dane makroekonomiczne czy branżowe) mogą nie przekładać się bezpośrednio na poprawę wyników – niemniej jednak oryginalny zbiór może posłużyć do wzbogacenia zbioru treningowego lub do inżynierii cech.

**Możliwe dodatkowe dane zewnętrzne:** Poza wspomnianym zbiorem oryginalnym z Kaggle, uczestnicy rozważali również wykorzystanie **analogicznych rzeczywistych danych kredytowych** dla inspiracji lub pretrenowania modeli. Przykładowo, publicznie dostępne dane z serwisu pożyczkowego (np. Lending Club) zawierające podobne atrybuty mogłyby potencjalnie pomóc w lepszym zrozumieniu zależności. Należy jednak pamiętać, że dane konkursowe są syntetyczne, więc bezpośrednie łączenie ich z prawdziwymi może być trudne. W praktyce większość uczestników skupiła się na zbiorze oryginalnym zapewnionym przez organizatorów – Kaggle otwarcie umożliwiło jego użycie w konkursie, co wielu wykorzystało do porównań dystrybucji cech i oceny, czy dodatkowe cechy z oryginału mogą poprawić model. Niektórzy próbowali np. **dokleić dane oryginalne do treningowych** (po uprzednim ograniczeniu do wspólnych kolumn) lub **wytrenować model na zbiorze oryginalnym i użyć go do wygenerowania cech/predykcji** dla danych konkursowych. Przykładowo, padła sugestia, by użyć modelu TabPFN nauczonego na oryginale do wygenerowania wstępnych przewidywań, a następnie dobudować model boostingowy korygujący reszty błędów[\[6\]](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/617692#:~:text=One%20idea%20is%20to%20use,then%20boost%20over%20the). Takie kreatywne podejścia pokazują, że oryginalny zbiór danych stanowi cenne źródło informacji – zarówno do **walidacji pomysłów** (np. porównania ważności cech w danych oryginalnych i syntetycznych), jak i do **rozszerzenia treningu**.

Podsumowując, kluczowym dodatkowym źródłem danych jest **zbiór Loan Prediction 2025** (dostępny w sekcji Datasets na Kaggle), zawierający szerszy zakres cech niż zbiór konkursowy. W miarę potrzeb można się także wspomóc **danymi domenowymi** – np. definicjami kategorii punktacji kredytowej, typowych przedziałów DTI czy średnimi stopami procentowymi – aby lepiej ukierunkować tworzenie cech (choć same dane zewnętrzne nie są bezpośrednio dołączalne z uwagi na brak identyfikatorów klientów czy dat w zbiorze).

## Analiza publicznych notebooków: transformacje cech, inżynieria cech, preprocessing i modelowanie

Prześledzenie publicznych notebooków konkursowych ujawnia szereg wspólnych praktyk w zakresie przygotowania danych i budowy modeli. Poniżej zestawiono najważniejsze obserwacje:

* **Przekształcenia i encoding cech kategorycznych:** Większość rozwiązań stosowała proste metody kodowania zmiennych kategorycznych, bazując na fakcie, że modele drzewiaste dobrze radzą sobie z etykietami liczbowymi. Typowym podejściem było użycie **Label Encoding** – zamiana kategorii na kody liczbowe dla każdej kolumny typu obiektowego. Często wykonywano to jednocześnie na zbiorze treningowym i testowym, aby zachować spójne mapowanie kategorii[\[7\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=def%20optimized_preprocessing%28train_df%2C%20test_df%29%3A%20,object%27%5D%29.columns). Przykładowo, jeden z czołowych uczestników zastosował label encoding przez połączenie kolumn kategorii z train i test, dopasowanie encodera, a następnie transformację wartości w obu zbiorach[\[8\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=%23%20Simple%20label%20encoding%20,object%27%5D%29.columns). Dzięki temu uniknięto problemu niespójnych etykiet (ważne przy kategoriach występujących tylko w testach). Rzadziej stosowano one-hot encoding (ze względu na dużą liczbę rekordów i sprawność modeli gradient boosting z kodami etykiet). Niektóre cechy kategoryczne były poddawane **dalszej obróbce**: np. cecha grade\_subgrade (łącząca literową ocenę kredytu i subkategorię) była często **rozdzielana na dwie cechy** – osobno grade (np. A, B, C...) i subgrade\_num (np. 1–5) – co umożliwiało modelowi uchwycenie wpływu ogólnej oceny kredytowej niezależnie od szczegółowego ranku. Po rozdzieleniu przypisywano tym cechom porządkową wartość liczbową (np. A=1, B=2… dla grade, oraz rzeczywistą wartość liczbową subgrade). Takie rozbicie to prosta forma **transformacji istniejącej cechy** w celu lepszego wykorzystania informacji przez model.

* **Przekształcenia cech numerycznych:** Zmiennych liczbowych w danych było stosunkowo niewiele, a algorytmy drzewiaste nie wymagają skalowania, dlatego większość uczestników pozostawiała je w formie surowej. Mimo to, w analizach EDA zwracano uwagę na rozkłady – np. **dochody (annual\_income)** i **kwoty pożyczek (loan\_amount)** miały silne skośności (dużo mniejszych kwot i nieliczne duże wartości). W niektórych notebookach eksperymentowano z **transformacją logarytmiczną** tych cech, aby zmniejszyć wpływ skrajnych wartości (np. użycie log10(annual\_income) zamiast wartości bezpośredniej). Inni proponowali dyskretyzację dochodu czy kwoty pożyczki na przedziały (np. niski/średni/wysoki) – zwłaszcza w kontekście modeli liniowych. Ogólnie jednak metody oparte na drzewach (XGBoost, LightGBM, itp.) potrafią same znaleźć odpowiednie punkty podziału, więc ręczne skalowanie nie było powszechne. Istotniejsze okazało się tworzenie **nowych kombinacji cech numerycznych**, o czym niżej.

* **Inżynieria cech (tworzenie nowych zmiennych):** Uczestnicy intensywnie eksperymentowali z dodatkowymi cechami wyprowadzonymi z istniejących kolumn, wykorzystując znajomość domeny finansowej. Oto przykłady ciekawszych **nowo utworzonych cech** inspirowanych analizami publicznych rozwiązań:

* **Miesięczny dochód i obciążenie długiem:** Ponieważ oryginalny zbiór danych zawierał zarówno annual\_income, jak i monthly\_income, zauważono, że miesięczny dochód można łatwo odtworzyć w danych konkursowych (np. monthly\_income \= annual\_income / 12). Mając to, niektórzy obliczali następnie **miesięczne zobowiązania dłużne**: monthly\_debt \= monthly\_income \* debt\_to\_income\_ratio. Równoważnie, od razu definiowano **“pozostający dochód”** po spłacie długów jako remaining\_income \= monthly\_income \* (1 \- debt\_to\_income\_ratio). Taka cecha mierzy **zdolność spłaty** – ile dochodu zostaje klientowi po uwzględnieniu istniejących zobowiązań. W literaturze finansowej podobny wskaźnik bywa nazywany *payment capacity*. Jeden z notebooków przedstawił go wzorem: payment\_capacity \= (annual\_income/12) \* (1 \- debt\_to\_income\_ratio)[\[9\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length). Intuicyjnie, im większy pozostający dochód (relatywnie do nowej raty), tym większa szansa spłaty pożyczki.

* **Wskaźnik wykorzystania kredytu:** Inna zaproponowana cecha łączyła **zdolność kredytową z obciążeniem długiem**. Przykładowo, zdefiniowano credit\_utilization \= debt\_to\_income\_ratio \* (1 \- credit\_score/850)[\[9\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length). Pomysł polegał na tym, że wysoki DTI po skorygowaniu o wysoki/niski credit score da metrykę “ryzyka kredytowego” – wysoka wartość oznacza kogoś z dużymi długami i niską oceną kredytową (sygnał wysokiego ryzyka). Choć metryka ta jest dość złożona, stanowi próbę wychwycenia nieliniowej interakcji: jeśli zarówno DTI jest wysokie, *i* jednocześnie credit score niski, to sytuacja jest znacznie gorsza niż wynikałoby z każdej cechy osobno.

* **Stosunek kwoty pożyczki do dochodu:** Powszechnie sugerowaną cechą była relacja zadłużenia do dochodu. Najprostszą formą jest **loan\_to\_income \= loan\_amount / annual\_income** – określa ona, jak dużą część rocznego dochodu stanowi wnioskowana kwota. Wysoka wartość oznacza relatywnie dużą pożyczkę względem zarobków, co może wiązać się z większym ryzykiem. Niektórzy modyfikowali tę cechę w celu uzyskania lepszej dynamiki – np. używając pierwiastka kwadratowego z dochodu: loan\_to\_income\_velocity \= loan\_amount / sqrt(annual\_income)[\[10\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df%5B%27credit_utilization%27%5D%20%3D%20df%5B%27debt_to_income_ratio%27%5D%20,df%5B%27employment_length). Taka transformacja zmniejsza wpływ skrajnie wysokich dochodów (dla bardzo zamożnych pożyczkobiorców nawet duża pożyczka nie jest problemem).

* **Wskaźniki “ryzyka” łączące oprocentowanie i zdolność kredytową:** Oprocentowanie pożyczki często koreluje z ryzykiem kredytowym (wyższe stopy dla bardziej ryzykownych klientów). Aby wydobyć informację, czy oprocentowanie jest “adekwatne” do oceny kredytowej, zaproponowano cechę typu **risk\_adjusted\_return \= interest\_rate / f(credit\_score)**. W jednym podejściu konkretnie użyto formuły: risk\_adjusted\_return \= (interest\_rate \* 100\) / (credit\_score / 10\)[\[10\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df%5B%27credit_utilization%27%5D%20%3D%20df%5B%27debt_to_income_ratio%27%5D%20,df%5B%27employment_length). Po uproszczeniu jest to proporcjonalne do interest\_rate \* 10 / credit\_score. Wskaźnik ten rośnie, gdy stopa procentowa jest wysoka jak na dany poziom punktacji kredytowej – co może sygnalizować, że pożyczkobiorca został oceniony jako ryzykowny (skoro otrzymał znacznie wyższe oprocentowanie niż typowe dla jego score).

* **Inne cechy interakcyjne:** Pojawiły się też bardziej nietypowe propozycje. Przykładowo, wykorzystując dane oryginalne o długości zatrudnienia, zdefiniowano debt\_momentum \= debt\_to\_income\_ratio \* employment\_length[\[11\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length) – ideą było uwzględnienie, że ryzyko związane z długiem może być łagodzone przez stabilność zatrudnienia (dłuższy staż pracy). W danych konkursowych brak jednak jawnej cechy liczbowej *employment\_length* – status zatrudnienia jest podany kategorialnie (np. *Employed, Self-employed, Unemployed, Student* itp.). Mimo to, co poniektórzy próbowali zakodować tę informację w przybliżeniu (np. przypisując bezrobotnym wartość 0, a pracującym szacunkowy średni staż na podstawie kategorii), aby móc skorzystać z podobnej cechy. Inny przykład cechy to *„monthly\_installment”* – oryginalny zbiór miał kolumnę raty miesięcznej (installment), której zabrakło w danych syntetycznych. Niektórzy uczestnicy rozważali przybliżenie raty na podstawie kwoty, oprocentowania i założeń co do okresu spłaty (np. 36 lub 60 miesięcy), jednak bez dokładnych danych o terminach spłaty takie wyliczenia obarczone są błędem.

Warto zauważyć, że nie wszystkie wymyślne cechy przyniosły oczekiwane korzyści. W przytoczonym publicznym artykule jeden z uczestników przyznał, że jego **bardzo złożone cechy finansowe nie uogólniły się dobrze na zbiorze testowym** – mimo eleganckiej konstrukcji matematycznej powodowały nadmierne dopasowanie do danych treningowych[\[12\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=My%20%E2%80%9Csophisticated%E2%80%9D%20financial%20features%20like,generalize%20to%20the%20test%20set). Ostatecznie okazało się, że **czasem mniej znaczy więcej**: proste cechy (lub nawet ograniczenie ich liczby) bywały skuteczniejsze[\[13\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Conclusion). Niemniej jednak, powyższe przykłady stanowią cenną inspirację – pokazują, jak zrozumienie zależności ekonomicznych (dochód vs zadłużenie, ocena kredytowa vs oprocentowanie, itp.) może prowadzić do propozycji nowych zmiennych potencjalnie poprawiających rozróżnialność pozytywnych i negatywnych przypadków.

* **Techniki preprocessingu:** W kontekście czyszczenia danych uczestnicy nie musieli zajmować się brakującymi wartościami – zarówno zbiór syntetyczny konkursowy, jak i oryginalny zostały **całkowicie wyczyszczone z braków** (co potwierdziła analiza EDA: 0 braków we wszystkich kolumnach). Nie stwierdzono też oczywistych błędów czy anomalii (np. ujemne dochody). Część prac sprawdzała występowanie **wartości odstających** – np. bardzo wysokich dochodów lub skrajnie niskich punktacji kredytowych – ale uznano je za realistyczne i pozostawiono, licząc że modele drzewiaste poradzą sobie z nimi. Warto wspomnieć o **problemie niezbalansowanej klasy docelowej**: tylko \~20% przykładów to niespłacone pożyczki (0), reszta \~80% to spłacone (1)[\[2\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Target%20Distribution%3A%20loan_paid_back%20%3D%201,2). Taki stosunek (\~4:1) nie jest skrajny, ale wymaga uwagi. Niektóre notebooki próbowały radzić sobie z tym poprzez **nadpróbkowanie danych mniejszości** (np. SMOTE) – jednak jak ostrzegł jeden z autorów, nieumiejętne użycie tego przed podziałem walidacyjnym spowodowało poważny **wyciek danych i zawyżenie wyników CV**[\[14\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=,LEAKAGE). Bardziej skuteczne okazało się podejście polegające na **nadaniu wag klasom** w algorytmach modelowania (np. parametry class\_weight ustawione na 'balanced' w LightGBM)[\[15\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=metric%3D%27auc%27%2C%20boosting_type%3D%27gbdt%27%2C%20class_weight%3D%27balanced%27%2C%20%20,1%20%29%20return%20model.fit%28X_train%2C%20y_train). Zbalansowanie wag pozwoliło modelom skupić się mocniej na rzadkiej klasie „default”, co znacząco poprawiło wyniki na leaderboardzie bez sztucznego generowania nowych punktów danych. W sumie, najlepsze praktyki preprocessingowe sprowadzały się do: rzetelnego **stratyfikowanego podziału walidacyjnego** (z zachowaniem proporcji klas), prostego kodowania kategorii, usunięcia zbędnych kolumn (np. ID), ewentualnie standaryzacji etykiet tekstowych (choć tu nie było takich pól) oraz rozważnego podejścia do niezbalansowania (wagi klas zamiast agresywnego resamplingu).

* **Podejścia modelowania:** W publicznych notebookach dominowały **ensemble’owe modele decyzji drzewiastych**. Najczęściej wykorzystywano algorytmy **Gradient Boosting** – w szczególności **LightGBM**, **XGBoost** oraz **CatBoost** – ze względu na ich skuteczność w danych tabelarycznych i wbudowaną obsługę cech kategorycznych (CatBoost) lub łatwość radzenia sobie z label encoded features. Wielu uczestników trenowało **kilka modeli bazowych** i następnie próbowało je łączyć. Popularnym podejściem było proste **ensemble (średnia ważona)** najlepszych modeli albo dwu-poziomowy stacking. Przykładowo, jeden ze topowych wyników uzyskano przez zbudowanie czterech modeli bazowych (dwa różne modele XGBoost, jeden LightGBM i jeden CatBoost), a następnie zestackowanie ich predykcji meta-modelem (np. regresją logistyczną lub kolejnym małym XGBoostem)[\[16\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=It%20started%20with%20what%20seemed,make%20any%20data%20scientist%20proud). Tak złożone podejście osiągało rewelacyjne wyniki na walidacji (auc \~0.98), jednak niosło ryzyko przeuczenia – co faktycznie zdarzyło się, jeśli walidacja nie była odpowiednio zaprojektowana[\[17\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=But%20the%20public%20leaderboard%20told,was%20barely%20above%20random%20guessing). Finalnie, wiele rozwiązań odniosło sukces stosując **pojedynczy silny model** (często LightGBM) z właściwymi parametrami, wagami klas i minimalnym tuningiem. Najlepsze zgłoszenia osiągały około **0.922–0.924 AUC** na publicznym leaderboardzie, głównie dzięki dopracowanej inżynierii cech i odpowiednim parametrom modeli boostingowych. Warto dodać, że nieliczni próbowali też modeli typu **TabNet, sieci neuronowe** czy **TabPFN**, ale przy tak dużym zbiorze danych to właśnie sprawdzone algorytmy GBDT okazały się najskuteczniejsze. AutoML (np. FLAML, H2O, czy AutoGluon) również był testowany w niektórych notebookach – osiągał przyzwoite wyniki (\~0.92 AUC) z minimalnym nakładem pracy[\[18\]](https://www.kaggle.com/code/gauravduttakiit/org-pss5e11-fe-flaml-roc-auc#:~:text=Org%2BPSS5E11%20%3A%20FE%2BFLAML%20%3A%20roc_auc,train), choć manualnie strojone modele nieco go przebijały. Ogólnie, kluczem do wysokich wyników okazało się **połączenie mocnych modeli z bogatym zbiorem cech** – nawet kosztem zwiększenia złożoności, byle uniknąć błędów walidacji.

## Proponowane transformacje istniejących cech oraz nowe cechy

Na podstawie powyższej analizy można zaproponować szereg konkretnych przekształceń cech istniejących w danych konkursowych oraz zaprojektować nowe cechy, które mogą zwiększyć moc predykcyjną modeli. Poniżej przedstawiono podsumowanie takich propozycji. W **Tabeli 1** zebrano przykłady, gdzie dla wybranych oryginalnych kolumn z danych wskazano możliwe **transformacje** (zmiany reprezentacji lub skali cechy) oraz **nowe konstrukty cech**, które można z nich wyprowadzić (także poprzez połączenie z innymi kolumnami).

**Tabela 1\.** Przykłady oryginalnych cech z konkursu i propozycje ich transformacji oraz nowych cech:

| Oryginalna cecha | Możliwe transformacje/encoding | Proponowane nowe cechy |
| :---- | :---- | :---- |
| **annual\_income** (roczny dochód) | \- transformacja logarytmiczna (np. log10) dla zmniejszenia skośności\<br\>- binning na kategorie dochodu (np. niski/średni/wysoki) | \- *monthly\_income*: miesięczny dochód \= annual\_income/12 (jeśli potrzebny)\<br\>- *income\_bracket*: kategoria dochodu (np. \<=50k, 50-100k, \>100k USD) do uchwycenia nieliniowych efektów dochodu\<br\>- *loan\_to\_income*: stosunek kwoty pożyczki do dochodu (wymaga loan\_amount) |
| **debt\_to\_income\_ratio** (DTI) | \- zamiana na % (jeśli obecnie w ułamku) dla interpretowalności\<br\>- opcjonalnie binning (np. DTI \< 20%, 20-40%, \>40%) | \- *monthly\_debt*: szacowana miesięczna obsługa długu \= DTI \* monthly\_income\<br\>- *remaining\_income*: dochód po obsłudze długu \= annual\_income*(1 \- DTI) (miara “marginesu” finansowego klienta)[\[19\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27credit_score%27%5D%20%2F%20850)\<br\>-* high\_DTI\_flag\*: flaga 1/0 czy DTI przekracza pewien próg (np. 40%) |
| **credit\_score** (ocena kredytowa) | \- pozostawienie jako zmienna numeryczna (modele drzewa znajdą progi)\<br\>- ewentualnie **bining punktacji** na przedziały jakości (np. \<600 \= słaby, 600-700 \= średni, \>700 \= dobry) | \- *credit\_score\_norm*: znormalizowana punktacja (np. /850) żeby łatwiej łączyć z innymi cechami\<br\>- *credit\_grade*: kategoria punktacji (z biningu powyżej) jako oddzielna cecha kategoryczna\<br\>- *credit\_risk\_index*: kombinacja credit\_score z inną cechą, np. interest\_rate – patrz *risk\_adjusted\_return* poniżej |
| **interest\_rate** (oprocentowanie) | \- jeśli w formie dziesiętnej, można przemnożyć przez 100 (lepsza interpretacja jako %)\<br\>- nie wymaga skalowania dla modeli drzewiastych | \- *risk\_adjusted\_return*: np. interest\_rate \* 100 / (credit\_score/10) – mierzy wysokość oprocentowania skorygowaną o jakość kredytową[\[10\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df%5B%27credit_utilization%27%5D%20%3D%20df%5B%27debt_to_income_ratio%27%5D%20,df%5B%27employment_length)\<br\>- *high\_rate\_flag*: flaga czy oprocentowanie \> mediany/pewnego progu (sygnalizuje ryzykowną pożyczkę)\<br\>- *(interest\_rate \* loan\_amount)*: można rozważyć iloczyn stopy i kwoty jako aproksymację kosztu odsetek rocznie (pomocne przy braku cechy installment) |
| **loan\_amount** (kwota pożyczki) | \- transformacja log10(loan\_amount) dla zmniejszenia wpływu dużych kwot\<br\>- binning kwoty (np. mała \<5k, średnia 5-20k, duża \>20k USD) | \- *loan\_to\_income*: stosunek kwoty pożyczki do rocznego dochodu (wymaga annual\_income)\<br\>- *loan\_to\_income\_velocity*: loan\_amount / sqrt(annual\_income) – alternatywny skalowany wskaźnik zadłużenia[\[20\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df%5B%27risk_adjusted_return%27%5D%20%3D%20%28df%5B%27interest_rate%27%5D%20,df%5B%27employment_length)\<br\>- *installment\_est*: szacowana rata miesięczna – **uwaga:** wymaga założenia dot. okresu; np. jeśli założyć 36 mies., można estymować ratę z wzoru kredytowego |
| **grade\_subgrade** (ocena kredytu) | \- rozdzielenie na dwie cechy: **grade** (literka A-G) i **subgrade** (numer 1-5)\<br\>- zakodowanie **grade** jako cechy porządkowej (A \> B \> C ... \> G) zgodnie z ryzykiem\<br\>- **subgrade** traktowany numerycznie (1–5) lub jako kategoria | \- *grade\_numeric*: mapowanie grade na liczby, np. A=7,...,G=1 (oddaje ranking jakości kredytu)\<br\>- *subgrade\_bin*: podział subgrade na 2 kategorie, np. {1-3 vs 4-5} jeśli niektóre subgrade są dużo gorsze\<br\>- *grade\_x\_int\_rate*: interakcja kategorii grade z oprocentowaniem – np. różnica między rzeczywistym interest\_rate a średnim dla danego grade (pokazuje czy klient ma lepszą/gorszą stawkę niż typowa w tej kategorii) |
| **employment\_status** (status zatrudnienia) | \- zakodowanie label encoderem (np. 0=Unemployed, 1=Student, 2=Employed, 3=Self-employed, ... zgodnie z hierarchią stabilności)\<br\>- ewentualnie zgrupowanie rzadkich kategorii („Retired”/„Other”) jeśli występują, by uniknąć kategorii z małą licznością | \- *employment\_length\_est*: oszacowana liczba lat zatrudnienia – jeśli employment\_status zawiera info (np. „Employed 10+ years”), wyciągnąć wartość liczbową\<br\>- *stable\_job\_flag*: flaga 1/0 czy status wskazuje stałe zatrudnienie (vs np. student, bezrobotny)\<br\>- *debt\_momentum*: (przy założeniu posiadania employment\_length) \= debt\_to\_income\_ratio \* employment\_length – wskaźnik obciążenia długiem skorygowany o staż pracy[\[11\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length) |
| **loan\_purpose** (cel pożyczki) | \- kategoria tekstowa: można zastosować label encoding lub one-hot (jeśli modele liniowe)\<br\>- alternatywnie zgrupować cele w szersze kategorie (np. konsumpcyjne vs edukacja vs konsolidacja długów) | \- *purpose\_{X}*: każdą często występującą kategorię można zamienić na binarną cechę (one-hot), np. purpose\_home\_improvement \= 1/0\<br\>- *debt\_consolidation\_flag*: przykład cechy grupującej – flaga czy cel to konsolidacja zadłużenia (to najczęstszy cel, potencjalnie inny profil ryzyka niż np. pożyczka na edukację)\<br\>- *(purpose x grade)*: interakcja jakości kredytu z celem – np. niektóre cele przy niskim grade mogą być bardziej ryzykowne niż inne |

*Wyjaśnienie:* Powyższe propozycje obejmują zarówno proste transformacje (np. skalowanie logarytmiczne, kodowanie kategorii), jak i **cechy domenowe** wyprowadzone ze zrozumienia finansów (np. wskaźniki relacji dochodu do długu, kombinacje oprocentowania i oceny kredytowej). Wprowadzenie takich cech może pomóc modelom uchwycić złożone zależności nieliniowe. Każdą nową cechę należy jednak zweryfikować na walidacji – upewnić się, że rzeczywiście poprawia ona metrykę, a nie wprowadza szumu czy zależności, których model sam by nie uchwycił. Z doświadczeń uczestników wynika, że **kluczowe cechy prognostyczne** w tym zadaniu to m.in. ocena kredytowa, DTI, dochód, kwota, oprocentowanie oraz związana z nimi kategoria grade. Dodanie przemyślanych cech interakcyjnych (jak *loan\_to\_income* czy *remaining\_income*) może polepszyć AUC o kilka punktów tysięcznych, co w realiach Kaggle bywa na wagę miejsc w rankingu.

Ponadto, analizując dodatkowe kolumny dostępne w oryginalnym zbiorze danych, można zastanowić się nad ich **pośrednim wykorzystaniem**. Choć nie możemy ich bezpośrednio dodać do danych konkursowych (bo tam ich brakuje dla nowych rekordów), można wyciągnąć z nich wiedzę. Przykładowo, oryginalne cechy num\_of\_delinquencies (liczba zaległości) czy public\_records (negatywne wpisy w rejestrach) są silnie związane z ryzykiem. Można więc spróbować zasymulować ich wpływ poprzez inne dostępne cechy – np. wysoki credit\_score prawdopodobnie koreluje z brakiem delikfencji, a skrajnie niski mógłby sugerować ich obecność. Podobnie current\_balance (obecne saldo zadłużenia) było w oryginale – jego brak można częściowo zastąpić cechą *debt\_to\_income\_ratio* (która odzwierciedla poziom zadłużenia względnie do dochodu). W ten sposób **nowe cechy wyprowadzone z istniejących mogą kompensować brakujące informacje**.

## Optymalizacja poza automatyzacją AutoGluon

Użytkownik planuje wykorzystać bibliotekę AutoGluon z presetem hyperparameters='zeroshot' do trenowania modelu, co oznacza automatyczne trenowanie szeregu modeli bazowych bez ręcznego strojenia hiperparametrów. W takiej sytuacji szczególnie istotne stają się wszelkie usprawnienia **przed etapem modelowania**, gdyż AutoGluon sam z siebie nie przeprowadzi skomplikowanej inżynierii cech. Poniżej wskazano obszary, na które warto zwrócić uwagę, aby poprawić wyniki modelu **poza samą automatyzacją** procesu uczenia:

* **Selekcja i redukcja cech:** Choć AutoGluon spróbuje wielu modeli, nie gwarantuje, że nieistotne lub redundantne cechy zostaną pominięte. Dlatego zaleca się przeprowadzenie wstępnej selekcji cech. Na podstawie EDA można usunąć cechy, które są *wysoce skorelowane* z innymi lub nie wnoszą informacji. Przykładowo, jeśli w danych konkursowych pojawiłyby się zarówno annual\_income jak i monthly\_income, należałoby świadomie użyć tylko jednej (aby nie dublować informacji). W naszym zbiorze akurat miesięczny dochód nie jest jawnie dany – ale analogicznie, cecha grade\_subgrade po rozbiciu generuje dwie kolumny silnie ze sobą powiązane (gdyż subgrade jest uszczegółowieniem grade). Można rozważyć, czy model lepiej sobie radzi używając obu, czy wystarczy np. sama ogólna ocena grade. Innym przykładem jest *interest\_rate vs grade*: są one skorelowane (lepszy grade zwykle oznacza niższe oprocentowanie). Nie oznacza to bynajmniej, że którąś należy usunąć – ale warto być świadomym tej zależności i ewentualnie przetestować wpływ usunięcia jednej z nich na wyniki modelu (czasem model uczy się lepiej z jednym sygnałem zamiast dwóch skorelowanych). AutoGluon co prawda potrafi ocenić ważność cech po treningu modeli, ale wykonanie **manualnej selekcji cech ex ante** (np. odrzucenie cech o zerowej wariancji lub niemających teoretycznego wpływu na default) może skrócić czas treningu i zmniejszyć ryzyko nadmiernego dopasowania.

* **Zaawansowane przekształcenia cech (przed AutoGluon):** Warto wprowadzić wszystkie przemyślane **transformacje i nowe cechy** (jak opisane w poprzedniej sekcji) przed przekazaniem danych do AutoGluon. Narzędzie to automatycznie dokona pewnych podstawowych kroków – np. uzupełnienia ewentualnych braków, podstawowego encodingu kategorii – ale **nie wygeneruje złożonych cech interakcyjnych ani nie dokona skomplikowanych transformacji nieliniowych**. Z tego powodu, manualna inżynieria cech jest kluczowym uzupełnieniem AutoML. Na przykład, AutoGluon sam zakoduje kategorie jako liczby, lecz nie „domyśli się”, by podzielić grade\_subgrade na dwie kolumny – jeśli uznajemy to za istotne, musimy zrobić to ręcznie. Podobnie, autoML nie stworzy cechy typu *loan\_to\_income* czy *remaining\_income* bez wyraźnego wskazania. Te dodatkowe zmienne możemy następnie przekazać do AutoGluon tak, jakby były zwykłą częścią zbioru – będą brały udział w trenowaniu modeli tak samo jak oryginalne kolumny. Należy przy tym zachować ostrożność, by **nie wprowadzić wycieków**: wszelkie transformacje muszą być zdefiniowane wyłącznie na podstawie danych dostępnych podczas predykcji (np. nie można użyć informacji z loan\_paid\_back do stworzenia nowej cechy). Trzymając się standardowego pipeline’u (obliczenie nowych cech z danych wejściowych dla każdego zbioru osobno) unikniemy takiego błędu.

* **Balansowanie klasy i metryka modelu:** AutoGluon domyślnie optymalizuje określoną metrykę (dla klasyfikacji binarnej często accuracy lub logloss, chyba że wskażemy inaczej). W tym zadaniu kluczową metryką jest AUC (pole pod krzywą ROC). Warto więc **ustawić w AutoGluon metrykę ewaluacyjną na roc\_auc** – tak by automatycznie wybierał model dający najwyższe AUC na walidacji. Ponadto, jeśli to możliwe w presecie zeroshot, warto **przekazać informację o niezbalansowaniu klas**. Niektóre AutoML pozwalają np. ustawić balance\_classes=True lub przekazać parametry modeli bazowych z weightami. Jeżeli AutoGluon nie robi tego automatycznie, można samemu zwiększyć wagę klasy mniejszości w danych treningowych (np. poprzez *oversampling* klasy 0 lub poprzez duplikację/kopiowanie rekordów klasy 0, ostrożnie by nie przeciekać między foldami). Jednak bez tuningu hiperparametrów lepiej polegać na wbudowanych mechanizmach modeli – np. LightGBM i CatBoost użyte wewnątrz AutoGluon prawdopodobnie można tak skonfigurować. W przypadku braku takiej opcji, **rozważne undersampling/oversampling wewnątrz cross-validation** może pomóc (należy zapewnić, że nadpróbkowanie jest stosowane *tylko* na foldzie treningowym, a nie walidacyjnym, by uniknąć wycieku[\[14\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=,LEAKAGE)). Z doświadczeń konkursu wynika, że poprawne uwzględnienie niezbalansowania poprzez wagi potrafi podnieść AUC o znaczący margines (np. jeden z uczestników odnotował wzrost z \~0.91 do \~0.922 AUC po włączeniu wag klas w LightGBM[\[15\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=metric%3D%27auc%27%2C%20boosting_type%3D%27gbdt%27%2C%20class_weight%3D%27balanced%27%2C%20%20,1%20%29%20return%20model.fit%28X_train%2C%20y_train)).

* **Filtracja i czyszczenie danych wejściowych:** Przed użyciem AutoGluon warto wykonać ręczną inspekcję danych i usunąć potencjalne szkodliwe elementy. Na szczęście w tym zbiorze **nie stwierdzono rażących błędów** (jak duplikaty czy brakujące wartości). Gdyby jednak np. znaleziono duplikaty rekordów lub outliery odstające o rzędy wielkości (np. osoba z nielogicznie wysokim DTI \= 5 czy credit\_score \= 10000), rozważne byłoby ich usunięcie lub winsoryzacja przed trenowaniem modeli. Automatyczne narzędzia zazwyczaj nie eliminują takich anomalii, a mogą one zakłócić trening (choć modele drzewiaste są dość odporne na pojedyncze outliery). W kontekście danych syntetycznych raczej nie ma ekstremalnych błędów, ale profilaktyczna kontrola (którą użytkownik już zrobił w EDA) potwierdziła poprawność danych. Z punktu widzenia AutoGluon należy również **usunąć kolumnę ID** (jeśli jeszcze jest w danych), aby nie była ona brana jako cecha. AutoGluon zwykle sam ignoruje pola o oczywistej entropii zerowej, ale ID może wydawać się losowe – lepiej więc jawnie go wykluczyć.

* **Walidacja modelu i prostota rozwiązania:** AutoGluon (preset zeroshot) da szybkie wyniki, jednak warto zadbać o solidną walidację krzyżową własnych danych. Można np. samodzielnie podzielić dane treningowe na k-foldy (stratyfikowane) i uruchomić AutoGluon wielokrotnie na różnych foldach, aby upewnić się, że wyniki są stabilne. Ponieważ nie będziemy stroić hiperparametrów, **siła rozwiązania będzie zależeć głównie od cech**. Dlatego po wygenerowaniu nowych cech i transformacji, dobrze jest sprawdzić ich wpływ: np. uruchomić AutoGluon na surowych cechach vs na rozszerzonym zbiorze z nowymi cechami – i porównać AUC. Taka ablacja wskaże, które dodatki są korzystne. Czasami ograniczenie liczby cech do tych najbardziej informatywnych może wręcz poprawić działanie AutoML (mniej szumu do oceny). Ważne jest też, aby nie przekombinować: jak pokazała historia jednego z uczestników, **zbyt złożone pipeline’y potrafią dać złudnie świetne wyniki na CV, ale słabe na LB**, podczas gdy prostsze podejście z mniejszą liczbą cech i bezpieczniejszą walidacją wygrało[\[13\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Conclusion). Dlatego zalecamy iteracyjne podejście: dodawać cechy krokowo i obserwować efekty, trzymając się zasady, że każda dodatkowa komplikacja powinna być uzasadniona poprawą wyniku na walidacji.

Podsumowując, **poza automatycznym trenowaniem modeli** warto zainwestować czas w dopracowanie danych wejściowych. W przypadku użycia AutoGluon (zwłaszcza bez strojenia) różnicę może zrobić: dobrze przemyślana **inżynieria cech**, eliminacja zbędnych informacji, zapewnienie modelowi kontekstu przez cechy interakcyjne, oraz uwzględnienie specyfiki zadania (np. niezbalansowanej klasy) w sposobie treningu. Te ręczne optymalizacje w połączeniu z ensemble’owymi modelami trenowanymi automatycznie powinny przełożyć się na lepsze wyniki końcowe, nawet bez bezpośredniego tuningowania hiperparametrów przez użytkownika. Dzięki temu podejściu AutoGluon skupi się na tym, co najważniejsze, dysponując maksymalnie informatywnym zestawem cech przygotowanym w procesie wcześniejszej analizy.

**Źródła:** Analiza wykonana w oparciu o publiczne materiały Kaggle i wpisy uczestników, m.in. dane konkursowe i oryginalne (*Loan Prediction Dataset 2025*)[\[3\]](https://www.kaggle.com/code/ocwerfrancis/predicting-loan-payback#:~:text=,monthly_income%27%2C%20%27employment_status%27%2C%20%27debt_to_income_ratio%27%2C%20%27credit_score)[\[4\]](https://www.kaggle.com/code/stpeteishii/loan-payback-importance-compe-orgin-comparison#:~:text=...%20loan_dataset_20000.csv%27%29%20,current_balance%27%2C%20%27num_of_delinquencies%27%2C%20%27loan_term%27%2C%20%27public_records), dyskusje na forum Kaggle[\[1\]](https://github.com/mateuszk098/kaggle-notebooks#:~:text=%2A%20Playground%20Series%20S3E09%20,s3e9)[\[5\]](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/615065#:~:text=The%20origin%20dataset%20is%20here,So) oraz artykuł opisujący doświadczenia z konkursu[\[21\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Before%20diving%20into%20the%20modeling,fundamental%20challenge%20of%20this%20dataset)[\[9\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length)[\[15\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=metric%3D%27auc%27%2C%20boosting_type%3D%27gbdt%27%2C%20class_weight%3D%27balanced%27%2C%20%20,1%20%29%20return%20model.fit%28X_train%2C%20y_train). Powiązane fragmenty kodu i opisów z tych źródeł zostały przytoczone w tekście w celu zilustrowania kluczowych wniosków.

---

[\[1\]](https://github.com/mateuszk098/kaggle-notebooks#:~:text=%2A%20Playground%20Series%20S3E09%20,s3e9) GitHub \- mateuszk098/kaggle-notebooks: Bunch of notebooks collection from Kaggle competitions.

[https://github.com/mateuszk098/kaggle-notebooks](https://github.com/mateuszk098/kaggle-notebooks)

[\[2\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Target%20Distribution%3A%20loan_paid_back%20%3D%201,2) [\[7\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=def%20optimized_preprocessing%28train_df%2C%20test_df%29%3A%20,object%27%5D%29.columns) [\[8\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=%23%20Simple%20label%20encoding%20,object%27%5D%29.columns) [\[9\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length) [\[10\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df%5B%27credit_utilization%27%5D%20%3D%20df%5B%27debt_to_income_ratio%27%5D%20,df%5B%27employment_length) [\[11\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27employment_length) [\[12\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=My%20%E2%80%9Csophisticated%E2%80%9D%20financial%20features%20like,generalize%20to%20the%20test%20set) [\[13\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Conclusion) [\[14\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=,LEAKAGE) [\[15\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=metric%3D%27auc%27%2C%20boosting_type%3D%27gbdt%27%2C%20class_weight%3D%27balanced%27%2C%20%20,1%20%29%20return%20model.fit%28X_train%2C%20y_train) [\[16\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=It%20started%20with%20what%20seemed,make%20any%20data%20scientist%20proud) [\[17\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=But%20the%20public%20leaderboard%20told,was%20barely%20above%20random%20guessing) [\[19\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df,df%5B%27credit_score%27%5D%20%2F%20850) [\[20\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=df%5B%27risk_adjusted_return%27%5D%20%3D%20%28df%5B%27interest_rate%27%5D%20,df%5B%27employment_length) [\[21\]](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14#:~:text=Before%20diving%20into%20the%20modeling,fundamental%20challenge%20of%20this%20dataset) From 0.56 to 0.92 AUC: My Kaggle Loan Prediction Journey Through Class Imbalance and Overfitting | by Sanjay Bista | Nov, 2025 | Medium

[https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14](https://medium.com/@sanjaybista1010/from-0-56-to-0-92-auc-my-kaggle-loan-prediction-journey-through-class-imbalance-and-overfitting-ab80d4591f14)

[\[3\]](https://www.kaggle.com/code/ocwerfrancis/predicting-loan-payback#:~:text=,monthly_income%27%2C%20%27employment_status%27%2C%20%27debt_to_income_ratio%27%2C%20%27credit_score) Predicting Loan Payback \- Kaggle

[https://www.kaggle.com/code/ocwerfrancis/predicting-loan-payback](https://www.kaggle.com/code/ocwerfrancis/predicting-loan-payback)

[\[4\]](https://www.kaggle.com/code/stpeteishii/loan-payback-importance-compe-orgin-comparison#:~:text=...%20loan_dataset_20000.csv%27%29%20,current_balance%27%2C%20%27num_of_delinquencies%27%2C%20%27loan_term%27%2C%20%27public_records) Loan Payback Importance: Compe/Orgin Comparison \- Kaggle

[https://www.kaggle.com/code/stpeteishii/loan-payback-importance-compe-orgin-comparison](https://www.kaggle.com/code/stpeteishii/loan-payback-importance-compe-orgin-comparison)

[\[5\]](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/615065#:~:text=The%20origin%20dataset%20is%20here,So) Predicting Loan Payback | Kaggle

[https://www.kaggle.com/competitions/playground-series-s5e11/discussion/615065](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/615065)

[\[6\]](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/617692#:~:text=One%20idea%20is%20to%20use,then%20boost%20over%20the) Predicting Loan Payback \- Kaggle

[https://www.kaggle.com/competitions/playground-series-s5e11/discussion/617692](https://www.kaggle.com/competitions/playground-series-s5e11/discussion/617692)

[\[18\]](https://www.kaggle.com/code/gauravduttakiit/org-pss5e11-fe-flaml-roc-auc#:~:text=Org%2BPSS5E11%20%3A%20FE%2BFLAML%20%3A%20roc_auc,train) Org+PSS5E11 : FE+FLAML : roc\_auc \- Kaggle

[https://www.kaggle.com/code/gauravduttakiit/org-pss5e11-fe-flaml-roc-auc](https://www.kaggle.com/code/gauravduttakiit/org-pss5e11-fe-flaml-roc-auc)