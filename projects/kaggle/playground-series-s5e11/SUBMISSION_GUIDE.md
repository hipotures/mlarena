# Przewodnik Submission - Wytrenowane Modele

## ğŸ“‹ SprawdÅº wytrenowane eksperymenty

```bash
cd /mnt/ml/kaggle-fork1/projects/kaggle/playground-series-s5e11
./list_trained_experiments.sh
```

PrzykÅ‚adowy output:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Experiment ID      â”‚ Template        â”‚ Status   â”‚ Local CV                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ exp-20251121-024914â”‚ exp01-tier1     â”‚ completedâ”‚ 0.93456                 â”‚
â”‚ exp-20251121-031527â”‚ exp02-encoding  â”‚ completedâ”‚ 0.94123                 â”‚
â”‚ exp-20251121-044312â”‚ exp03-lgbm-opt..â”‚ completedâ”‚ 0.93872                 â”‚
â”‚ exp-20251121-061845â”‚ exp04-stacking  â”‚ completedâ”‚ 0.94567                 â”‚
â”‚ exp-20251121-075234â”‚ exp05-transfer  â”‚ completedâ”‚ 0.93654                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Metoda 1: Submit pojedynczy eksperyment

### Krok 1: ZnajdÅº experiment_id
```bash
./list_trained_experiments.sh
```

### Krok 2: Submit wybrany eksperyment
```bash
./predict_and_submit.sh [experiment_id]
```

**PrzykÅ‚ad:**
```bash
./predict_and_submit.sh exp-20251121-044312
```

Co siÄ™ dzieje:
1. âœ… Åaduje wytrenowany model
2. âœ… Generuje predykcje na test set
3. âœ… Tworzy submission file
4. âœ… Uploaduje do Kaggle
5. âœ… Czeka 45s i fetchuje public score
6. âœ… Zapisuje wynik do submissions tracker

---

## ğŸ”„ Metoda 2: Submit wszystkie naraz

```bash
./submit_all_experiments.sh
```

**Co robi:**
- Znajduje wszystkie wytrenowane eksperymenty
- Sprawdza status (tylko `completed`)
- Submituje kaÅ¼dy po kolei
- Czeka miÄ™dzy submitami (5s delay)
- Pokazuje podsumowanie

**Output:**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“¦ Experiment 1: exp-20251121-024914
   Template: exp01-tier1
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Generating predictions...
[exp01_tier1_features] Generating predictions on 254569 samples...
[exp01_tier1_features] Predictions generated. Mean: 0.8010

âœ“ Submitted exp-20251121-024914

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“¦ Experiment 2: exp-20251121-031527
   Template: exp02-encoding
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
...

========================================
SUMMARY
========================================
Total experiments found: 5
Successfully submitted: 5
Skipped: 0
```

---

## ğŸ“Š SprawdÅº wyniki

### Lista wszystkich submissions
```bash
uv run python scripts/submissions_tracker.py --project playground-series-s5e11 list
```

### Ostatnie 10 submissions
```bash
uv run python scripts/submissions_tracker.py --project playground-series-s5e11 list | head -15
```

### PorÃ³wnanie z baseline
```bash
uv run python scripts/submissions_tracker.py --project playground-series-s5e11 list | grep -E "exp0[1-5]|baseline"
```

---

## ğŸ” Troubleshooting

### Problem: "No trained model found"

**Przyczyna:** Model nie zostaÅ‚ zapisany lub Å›cieÅ¼ka jest niepoprawna

**RozwiÄ…zanie:**
```bash
# SprawdÅº czy model istnieje
ls -la projects/kaggle/playground-series-s5e11/AutogluonModels/

# JeÅ›li brak, trzeba przetrenowaÄ‡:
uv run python scripts/ml_runner.py \
    --project playground-series-s5e11 \
    --template exp01-tier1 \
    --auto-submit \
    --wait-seconds 45
```

### Problem: "Model not completed"

**Przyczyna:** Trening siÄ™ nie zakoÅ„czyÅ‚ lub bÅ‚Ä…d

**RozwiÄ…zanie:**
```bash
# SprawdÅº status
./list_trained_experiments.sh

# JeÅ›li status = failed, sprawdÅº logi:
cat projects/kaggle/playground-series-s5e11/experiments/[experiment_id]/state.json
```

### Problem: Submission fails podczas upload

**Przyczyna:** Problem z Kaggle API lub submission format

**RozwiÄ…zanie:**
```bash
# SprawdÅº czy Kaggle credentials sÄ… OK
kaggle competitions list | head

# SprawdÅº czy competition jest active
kaggle competitions list | grep playground-series-s5e11

# Manual submission test (bez score fetch)
uv run python scripts/ml_runner.py \
    --project playground-series-s5e11 \
    --template exp01-tier1 \
    --experiment-id [exp_id] \
    --skip-score-fetch
```

### Problem: Score fetch timeout

**Przyczyna:** Kaggle processing jest wolny lub Chrome CDP nie dziaÅ‚a

**RozwiÄ…zanie:**
```bash
# ZwiÄ™ksz wait time
./predict_and_submit.sh [exp_id]
# Edytuj skrypt i zmieÅ„ WAIT_TIME=45 na WAIT_TIME=120

# Lub submituj bez score fetch:
uv run python scripts/ml_runner.py \
    --project playground-series-s5e11 \
    --template exp01-tier1 \
    --experiment-id [exp_id] \
    --skip-score-fetch
```

---

## ğŸ¯ Workflow Recommendation

### JeÅ›li masz 5 wytrenowanych eksperymentÃ³w:

1. **SprawdÅº local CV scores:**
   ```bash
   ./list_trained_experiments.sh
   ```

2. **Identify top 3 by CV:**
   - NajwyÅ¼szy CV = najpewniejszy kandydat
   - Ale overfitting moÅ¼e byÄ‡ problem!

3. **Submit top 3 najpierw:**
   ```bash
   ./predict_and_submit.sh [best_exp_id]
   ./predict_and_submit.sh [second_best_id]
   ./predict_and_submit.sh [third_best_id]
   ```

4. **Czekaj ~5 min i sprawdÅº public scores:**
   ```bash
   uv run python scripts/submissions_tracker.py --project playground-series-s5e11 list | head -10
   ```

5. **JeÅ›li top 3 sÄ… obiecujÄ…ce, submit resztÄ™:**
   ```bash
   ./submit_all_experiments.sh
   ```

6. **Wybierz zwyciÄ™zcÄ™:**
   - NajwyÅ¼szy public score
   - Najmniejszy gap (Local CV - Public)
   - Ten ktÃ³ry nie overfittuje

7. **Uruchom zwyciÄ™zcÄ™ na dÅ‚uÅ¼ej:**
   - Zmodyfikuj `time_limit` w `configs/templates.yaml`
   - ZmieÅ„ 5400 (1.5h) na 14400 (4h) lub 28800 (8h)
   - Przetrenuj ponownie

---

## ğŸ“ˆ Expected Results

| Eksperyment | Expected Local CV | Expected Public | Notes |
|-------------|------------------:|----------------:|-------|
| exp01-tier1 | 0.935-0.940 | 0.940-0.945 | Tier 1 features |
| exp02-encoding | 0.940-0.945 | 0.945-0.950 | +Target encoding |
| exp03-lgbm-optuna | 0.938-0.943 | 0.943-0.948 | Tuned LightGBM |
| exp04-stacking â­ | 0.943-0.948 | 0.947-0.952 | **BEST BET** |
| exp05-transfer | 0.937-0.942 | 0.941-0.946 | +Original data |

**Baseline:** Local 0.93309, Public 0.92434

**Target:** Public â‰¥ 0.945

---

## ğŸ”§ Manual Commands

JeÅ›li skrypty nie dziaÅ‚ajÄ…, uÅ¼yj bezpoÅ›rednio:

```bash
cd /mnt/ml/kaggle-fork1

# Submit konkretny eksperyment
uv run python scripts/ml_runner.py \
    --project playground-series-s5e11 \
    --template exp04-stacking \
    --experiment-id exp-20251121-061845 \
    --auto-submit \
    --wait-seconds 45

# Tylko predykcja (bez submit)
uv run python scripts/ml_runner.py \
    --project playground-series-s5e11 \
    --template exp04-stacking \
    --experiment-id exp-20251121-061845 \
    --skip-submit

# Submit bez score fetch (manual check later)
uv run python scripts/ml_runner.py \
    --project playground-series-s5e11 \
    --template exp04-stacking \
    --experiment-id exp-20251121-061845 \
    --auto-submit \
    --skip-score-fetch
```

---

**Good luck! ğŸ¯**
